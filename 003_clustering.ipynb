{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "003_clustering",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usugunawan15/DTI-Telkom/blob/master/003_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up2MQL0imvLy"
      },
      "source": [
        "*Data Science Course - Telkom Digital Talent Incubator*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4Mso6t1xnNI"
      },
      "source": [
        "# **Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KI-CeauxnNL"
      },
      "source": [
        "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFsQ5A-dxnNM"
      },
      "source": [
        "Here we model the clustering from customer income and spend data. We use this model to perform customer segmentation. We differentiate customers into the optimum number of groups based on their shared income and spend."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inQb-A87xnNO"
      },
      "source": [
        "### **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWjpVPPwxnNP"
      },
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNGuKcbExnNW"
      },
      "source": [
        "### **Import Raw Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amG-FUbBxnNW"
      },
      "source": [
        "# Import Dataset\n",
        "df_income = pd.read_csv('https://raw.githubusercontent.com/rc-dbe/bigdatacertification/master/dataset/clustering.csv')\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncTg-8rgxnNa"
      },
      "source": [
        "# Prints the Dataset Information\n",
        "df_income.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6P3xcaexnNd"
      },
      "source": [
        "# Prints Descriptive Statistics\n",
        "df_income.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2iFRVJ4xnNg"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vIOkyH8xnNh"
      },
      "source": [
        "First, we standardize the data to equalize the range and/or data variability. Feature standardization makes the values of each feature in the data have zero-mean (when subtracting the mean in the numerator) and unit-variance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiHuK6eRxnNh"
      },
      "source": [
        "# Importing Standardscalar Module \n",
        "from sklearn.preprocessing import StandardScaler \n",
        "\n",
        "# Set Name for StandardScaler as scaler\n",
        "scaler = StandardScaler() \n",
        "\n",
        "# Fit Standardization\n",
        "column_names = df_income.columns.tolist()\n",
        "df_income[column_names] = scaler.fit_transform(df_income[column_names])\n",
        "df_income.sort_index(inplace=True)\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-rZ-b7HxnNk"
      },
      "source": [
        "### **Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzrsVL3QxnNk"
      },
      "source": [
        "# Styling Plot\n",
        "sns.set() \n",
        "plt.rcParams['figure.figsize'] = (16, 9)\n",
        "\n",
        "# Visualizing the Data\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.title('Customer Segments')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Annual Spend')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUFokwaIxnNn"
      },
      "source": [
        "## **K-Means Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m4gRJybxnNo"
      },
      "source": [
        "Kmeans algorithm is an iterative algorithm that tries to partition the dataset into Kpre-defined distinct non-overlapping subgroups (clusters) where each data point belongs to only one group. It tries to make the inter-cluster data points as similar as possible while also keeping the clusters as different (far) as possible. It assigns data points to a cluster such that the sum of the squared distance between the data points and the clusterâ€™s centroid (arithmetic mean of all the data points that belong to that cluster) is at the minimum. The less variation we have within clusters, the more homogeneous (similar) the data points are within the same cluster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuxBhg7vxnNo"
      },
      "source": [
        "### **Search for the Optimum Number of Clusters (k)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7P4VHGNxnNo"
      },
      "source": [
        "# Transform Data Frame to Numpy Array\n",
        "income = df_income.to_numpy()\n",
        "income\n",
        "\n",
        "# Elbow Method\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(1,11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    kmeans.fit(income)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "  \n",
        "# Visualize \n",
        "plt.plot(range(1,11),wcss)\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('wcss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u7iBzUgxnNr"
      },
      "source": [
        "# Silhoutte Method\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "for n_cluster in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters=n_cluster).fit(income)\n",
        "    label = kmeans.labels_\n",
        "    sil_coeff = silhouette_score(income, label, metric='euclidean')\n",
        "    print('For n_clusters={}, The Silhouette Coefficient is {}'.format(n_cluster, sil_coeff))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkDXKDWXxnNv"
      },
      "source": [
        "### **Modeling K-Means**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-L5PPhHxnNw"
      },
      "source": [
        "# Apply the K-Means Model to the Data\n",
        "kmeans = KMeans(n_clusters=3, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "cluster = kmeans.fit_predict(income)\n",
        "\n",
        "# Visualising Clusters for k=3\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.scatter(income[cluster == 0, 0], income[cluster == 0, 1], s = 50, label = 'Cluster 1')\n",
        "plt.scatter(income[cluster == 1, 0], income[cluster == 1, 1], s = 50, label = 'Cluster 2')\n",
        "plt.scatter(income[cluster == 2, 0], income[cluster == 2, 1], s = 50, label = 'Cluster 3')\n",
        "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1],s=200,marker='s', alpha=0.7, label='Centroids')\n",
        "plt.title('Customer segments')\n",
        "plt.xlabel('Annual income')\n",
        "plt.ylabel('Annual spend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zegLJocuxnNz"
      },
      "source": [
        "# Add Cluster Information to the Raw Data\n",
        "df_income['cluster'] = cluster\n",
        "df_income"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bg7Rp3YJxnN1"
      },
      "source": [
        "# Save= Result\n",
        "df_income.to_csv('income_clusters.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZMMP5QIp7kF"
      },
      "source": [
        "## **Hierarchical Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QnoAhvr1m2a"
      },
      "source": [
        "Hierarchical clustering (also called hierarchical cluster analysis or HCA) is a method of cluster analysis which seeks to build a hierarchy of clusters. The endpoint is a set of clusters, where each cluster is distinct from each other cluster, and the objects within each cluster are broadly similar to each other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I12Urjo8p_eZ"
      },
      "source": [
        "# Modeling and Visualizing Clusters by Dendogram\n",
        "import scipy.cluster.hierarchy as sch\n",
        "dend = sch.dendrogram(sch.linkage(income, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Customer')\n",
        "plt.ylabel('Euclidean')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDGayf3V1wKa"
      },
      "source": [
        "# Apply the Hierarchical Clustering Model to the Dataset\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "hc = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "hcluster = hc.fit_predict(income)\n",
        "\n",
        "# Visualising Clusters for k=3\n",
        "sns.scatterplot(x='INCOME', y='SPEND', data=df_income)\n",
        "plt.scatter(income[hcluster == 0, 0], income[hcluster == 0, 1], s = 50, label = 'Cluster 1')\n",
        "plt.scatter(income[hcluster == 1, 0], income[hcluster == 1, 1], s = 50, label = 'Cluster 2')\n",
        "plt.scatter(income[hcluster == 2, 0], income[hcluster == 2, 1], s = 50, label = 'Cluster 3')\n",
        "plt.title('Clusters of customers')\n",
        "plt.xlabel('Annual Income')\n",
        "plt.ylabel('Annual Spend')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}